{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d01587-7584-40c1-a91f-90ad62e2a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ebaa2c-da6e-486a-88c6-5c1187e1b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def birdsEyeView(image):\n",
    "    \"\"\"\n",
    "    Schimba perspectiva imaginii in birdsEyeView\n",
    "    \"\"\"\n",
    "\n",
    "    top_left = [570, 458]\n",
    "    top_right = [720, 458]\n",
    "    bottom_left = [208, 665]\n",
    "    bottom_right = [1150, 665]\n",
    "\n",
    "    width, height = 1280, 220\n",
    "\n",
    "    pts1 = np.float32([top_left, top_right, bottom_left, bottom_right])\n",
    "    pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "    perspective_correction = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    perspective_correction_inv = cv2.getPerspectiveTransform(pts2, pts1)\n",
    "\n",
    "    result = cv2.warpPerspective(image, perspective_correction, (width, height), flags=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    return result, perspective_correction_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbe59ff-6f00-45d1-b8ae-5f24514408f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDetection(image):\n",
    "    \"\"\"\n",
    "    Pentru edge detection am folosit operatorul Scharr, care detecteaza derivate, gasind astfel diferentele de culoare din imagine\n",
    "    \"\"\"\n",
    "\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    channel = g\n",
    "    edge = cv2.Scharr(channel, cv2.CV_64F, 1, 0)\n",
    "    edge = np.absolute(edge) #folosim modulul pentru ca Scharr returneaza atat valori pozitive cat si negative, dar noi vrem sa stim doar daca avem un edge\n",
    "    edge = np.uint8(255 * edge / np.max(edge)) #convertim valorile in int si le facem sa fie intr-un interval 0-255, cum este necesar pentru o imagine cu un singur canal\n",
    "\n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3989030d-184a-4ace-a862-6154c9d60af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyDynamicThresholds(image):\n",
    "    \"\"\"\n",
    "    Am aplicat un threshold mai mare in partea de jos, unde imaginea e mai clara si un threshold mai mic in partea de sus, unde pixelii sunt mai \n",
    "    distorsionati\n",
    "    \"\"\"\n",
    "    binary = np.zeros_like(image)\n",
    "    #binary[image >= 50] = 255\n",
    "    threshold_up = 15\n",
    "    threshold_down = 60\n",
    "    threshold_delta = threshold_down-threshold_up\n",
    "    for y in range(220):\n",
    "        threshold_line = threshold_up + threshold_delta * y / 220\n",
    "        binary[y, image[y, :] >= threshold_line] = 255\n",
    "    return binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4c0362-ba6e-4dd0-bb39-c36c831a3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyHSLThreshold(image):\n",
    "    \"\"\"\n",
    "    Am folosit un threshold de 140 pentru channel-ul L din imaginea originala in format HSL\n",
    "    \"\"\"\n",
    "    imghsl = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    l_channel = imghsl[:,:,1]\n",
    "    _, thresholded_l_channel = cv2.threshold(l_channel, 140, 255, cv2.THRESH_BINARY)\n",
    "    return thresholded_l_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c96285a-eea2-4c37-bea7-b5fa91523eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateHistogram(image):\n",
    "    partial_img = image[image.shape[0] // 2:, :]\n",
    "    hist = np.sum(partial_img, axis=0)\n",
    "    size = len(hist)\n",
    "    max_index_left = np.argmax(hist[0:size//2])\n",
    "    max_index_right = np.argmax(hist[size//2:]) + size//2\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a67125d-809e-4c9d-bfaa-9129448b2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_steering_angle(hist):\n",
    "    \"\"\" Am calculat steering angle-ul folosindu-ne de valorile maxime din histograma, care ne indica unde ar fi benzile\"\"\"\n",
    "    midpoint = len(hist) // 2\n",
    "    left_peak = np.argmax(hist[:midpoint])\n",
    "    right_peak = np.argmax(hist[midpoint:]) + midpoint\n",
    "    offset = (left_peak + right_peak) / 2 - midpoint\n",
    "    max_offset = midpoint / 2\n",
    "    steering_angle = np.arctan(offset / max_offset) * 45 / np.pi\n",
    "    return steering_angle\n",
    "\n",
    "def draw_lane_lines_on_original(image, result, hist, perspective_correction_inv):\n",
    "    size = len(hist)\n",
    "    max_index_left = np.argmax(hist[:size//2])\n",
    "    max_index_right = np.argmax(hist[size//2:]) + size//2\n",
    "    \n",
    "    y_bottom = result.shape[0] - 1\n",
    "    left_line_bottom = [max_index_left, y_bottom]\n",
    "    right_line_bottom = [max_index_right, y_bottom]\n",
    "    left_line_top = [max_index_left, 0]\n",
    "    right_line_top = [max_index_right, 0]\n",
    "\n",
    "    pts_bird_eye = np.float32([left_line_bottom, left_line_top, right_line_bottom, right_line_top])\n",
    "    pts_original = cv2.perspectiveTransform(pts_bird_eye[None, :, :], perspective_correction_inv)[0]\n",
    "\n",
    "    pts_original = pts_original.astype(int)\n",
    "\n",
    "    roadImage_with_lines = image.copy()\n",
    "    cv2.line(roadImage_with_lines, tuple(pts_original[0]), tuple(pts_original[1]), (0, 255, 0), 5)\n",
    "    cv2.line(roadImage_with_lines, tuple(pts_original[2]), tuple(pts_original[3]), (0, 255, 0), 5)\n",
    "\n",
    "    steering_angle = calculate_steering_angle(hist)\n",
    "    \n",
    "    cv2.putText(roadImage_with_lines, f'Steering Angle: {steering_angle:.2f} degrees', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    return roadImage_with_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a195c37f-df99-4328-ba4a-e20580d433e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video_test.mp4')\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "height, width, _ = frame.shape\n",
    "\n",
    "out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    birds, perspective_correction_inv = birdsEyeView(frame)\n",
    "    edge = edgeDetection(birds)\n",
    "    thresh1 = applyDynamicThresholds(edge)\n",
    "    thresh2 = applyHSLThreshold(birds)\n",
    "    thresholdsCombined = cv2.bitwise_or(thresh1, thresh2)\n",
    "\n",
    "    hist = generateHistogram(thresholdsCombined)\n",
    "    frame_with_lines = draw_lane_lines_on_original(frame, birds, hist, perspective_correction_inv)\n",
    "    out.write(frame_with_lines)\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1c319-6f4e-4eca-ad7d-995954d02166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
